model:
  num_factor: 16
  hidden_sizes:
    - 400
    - 400
    - 400
  p_dropout: 0.5
  embedding_config:
    name: vanilla
  use_batchnorm: True

train_dataloader:
  dataset:
    name: kdd
    train_test_info: dataset/ctr/kdd/preprocessed/train_test_val_info.bin
    dataset_name: train
    dataset_path: dataset/ctr/kdd/track2/training.txt
    cache_path: .kdd
  num_workers: 8
  batch_size: 8192

val_dataloader:
  dataset:
    name: kdd
    train_test_info: dataset/ctr/kdd/preprocessed/train_test_val_info.bin
    dataset_name: val
    dataset_path: dataset/ctr/kdd/track2/training.txt
    cache_path: .kdd
  batch_size: 8192
  num_workers: 8

test_dataloader:
  dataset:
    name: kdd
    train_test_info: dataset/ctr/kdd/preprocessed/train_test_val_info.bin
    dataset_name: test
    dataset_path: dataset/ctr/kdd/track2/training.txt
    cache_path: .kdd
  batch_size: 8192
  num_workers: 8

run_test: false

checkpoint_path: checkpoints/deepfm_checkpoint.pth
num_epochs: 15
log_step: 1000
early_stop_patience: 3

weight_decay: 0.000001
learning_rate: 0.001
validate_step: 1

enable_profile: false

profilers:
  train_profiler:
    log_path: logs/lightgcn/train
    # Check pytorch document on profiler for more information
    # https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html#use-profiler-to-record-execution-events
    schedule:
      wait: 1
      warmup: 1
      active: 3
      repeat: 2
    record_shapes: true
    profile_memory: true
    with_stack: false
  val_profiler:
    log_path: logs/lightgcn/val
    schedule:
      wait: 1
      warmup: 1
      active: 3
      repeat: 2
    record_shapes: true
    profile_memory: true
    with_stack: true

logger:
  level: INFO
  log_folder: logs/deepfm
  log_name: original
